{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "criminal-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # neural network modules\n",
    "import torch.nn.functional as F  # activation functions\n",
    "import torch.optim as optim  # optimizer\n",
    "from torch.autograd import Variable # add gradients to tensors\n",
    "from torch.nn import Parameter # model parameter functionality \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "solar-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Fix target label\n",
    "label_encodings = {\n",
    "    'pants-fire': 0, \n",
    "    'false':      0, \n",
    "    'barely-true':1, \n",
    "    'half-true':  1, \n",
    "    'mostly-true':2,\n",
    "    'true':       2\n",
    "}\n",
    "df['target'] = df['label'].apply(lambda x: label_encodings[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stylish-radius",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = torch.load('train_bert.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-atlantic",
   "metadata": {},
   "source": [
    "### FakeBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "advance-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(output, targets):\n",
    "\n",
    "    predicted = [int(y_pred.detach().argmax(-1)) for y_pred in output]\n",
    "    targets = [int(y) for y in targets]\n",
    "    correct = sum(a==b for (a,b) in zip(predicted, targets))\n",
    "    accuracy = 100*correct/len(targets) \n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def train(data_X,\n",
    "          test_X,\n",
    "          data_y,\n",
    "          test_y,\n",
    "          num_epochs = 10,\n",
    "          batch_size = 100,\n",
    "          learning_rate = 0.01):\n",
    "    \n",
    "    # Instantiate model & optimization \n",
    "    model = FakeBERT()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Prepare test data\n",
    "    test_y = torch.Tensor(test_y.values).to(dtype=torch.long)\n",
    "    \n",
    "    # Iterate over epochs\n",
    "    for ep in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        # Iterate over batches\n",
    "        for i in range(data_X.shape[0]//batch_size):\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Declare features and target labels\n",
    "            X = data_X[i*batch_size:(i+1)*batch_size]\n",
    "            y = data_y[i*batch_size:(i+1)*batch_size].values\n",
    "            y = torch.Tensor(y).to(dtype=torch.long)\n",
    "\n",
    "            # Get predictions from model\n",
    "            pred = model(X)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            loss = loss_func(pred, y)\n",
    "\n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "        # Evaluate model\n",
    "        model.eval()\n",
    "            \n",
    "        # Evaluate on test data\n",
    "        test_pred = model(test_X)\n",
    "        test_accuracy = get_accuracy(test_pred, test_y)\n",
    "        \n",
    "        # Print accuracy\n",
    "        print(f\"Test accuracy: {test_accuracy} at epoch: {ep}\")\n",
    "\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "going-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FakeBERT, self).__init__()\n",
    "        \n",
    "        # Layer 1: Conv1D + Maxpool\n",
    "        self.conv_1 = nn.Conv1d(in_channels=25, out_channels=32, kernel_size=3, stride=1)\n",
    "        self.sigm_1 = nn.ReLU()\n",
    "        self.pool_1 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Layer 2: Conv1D + Maxpool\n",
    "        self.conv_2 = nn.Conv1d(in_channels=25, out_channels=32, kernel_size=4, stride=1)\n",
    "        self.sigm_2 = nn.ReLU()\n",
    "        self.pool_2 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Layer 3: Conv1D + Maxpool\n",
    "        self.conv_3 = nn.Conv1d(in_channels=25, out_channels=32, kernel_size=5, stride=1)\n",
    "        self.sigm_3 = nn.ReLU()\n",
    "        self.pool_3 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Layer 4: Conv1D + Maxpool\n",
    "        self.conv_4 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=5, stride=1)\n",
    "        self.sigm_4 = nn.ReLU()\n",
    "        self.pool_4 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Layer 5: Conv1D + Maxpool\n",
    "        self.conv_5 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=5, stride=1)\n",
    "        self.sigm_5 = nn.ReLU()\n",
    "        self.pool_5 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Layer 6: Fully Connected Layer \n",
    "        self.full_6 = nn.Linear(544,32)\n",
    "        self.sigm_6 = nn.Sigmoid()\n",
    "        \n",
    "        # Layer 7: Fully Connected Layer \n",
    "        self.full_7 = nn.Linear(32,3)\n",
    "        self.soft_7 = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Turn into tensor\n",
    "        x = torch.Tensor(x)\n",
    "        \n",
    "        # Generate the 3 1D conv layers\n",
    "        conv_1 = self.pool_1(self.sigm_1(self.conv_1(x)))        \n",
    "        conv_2 = self.pool_2(self.sigm_2(self.conv_2(x)))        \n",
    "        conv_3 = self.pool_3(self.sigm_3(self.conv_3(x)))\n",
    "        \n",
    "        # Concatenate the 3 layers\n",
    "        cat = torch.cat((conv_1,conv_2,conv_3),2)\n",
    "        \n",
    "        # Pass the concatenated output through 2 1D conv layers\n",
    "        conv_4 = self.pool_4(self.sigm_4(self.conv_4(cat)))        \n",
    "        conv_5 = self.pool_5(self.sigm_5(self.conv_5(conv_4)))  \n",
    "\n",
    "        # Flatten the output\n",
    "        flat = conv_5.flatten(start_dim=1)\n",
    "\n",
    "        # Pass through 2 fully connected layers\n",
    "        full_6 = self.sigm_6(self.full_6(flat))\n",
    "        full_7 = self.soft_7(self.full_7(full_6))\n",
    "        \n",
    "        return full_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "express-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_X = torch.transpose(pt[:10000],1,2)\n",
    "# test_X = torch.transpose(pt[10000:],1,2)\n",
    "\n",
    "data_X = pt[:10000]\n",
    "test_X = pt[10000:]\n",
    "data_y = df['target'][:10000]\n",
    "test_y = df['target'][10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dried-slovakia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 35.0 at epoch: 0\n",
      "Test accuracy: 35.0 at epoch: 1\n",
      "Test accuracy: 35.0 at epoch: 2\n",
      "Test accuracy: 35.0 at epoch: 3\n",
      "Test accuracy: 35.0 at epoch: 4\n",
      "Test accuracy: 35.0 at epoch: 5\n",
      "Test accuracy: 35.0 at epoch: 6\n",
      "Test accuracy: 35.0 at epoch: 7\n",
      "Test accuracy: 35.0 at epoch: 8\n",
      "Test accuracy: 35.0 at epoch: 9\n"
     ]
    }
   ],
   "source": [
    "test_data = train(data_X, test_X, data_y, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-monday",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

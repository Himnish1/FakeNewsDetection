{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elementary-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # neural network modules\n",
    "import torch.nn.functional as F  # activation functions\n",
    "import torch.optim as optim  # optimizer\n",
    "from torch.autograd import Variable # add gradients to tensors\n",
    "from torch.nn import Parameter # model parameter functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "painful-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "from bert_embedding import BertEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "premier-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "df_orig = pd.read_csv(\"train.csv\")\n",
    "df = df_orig.iloc[:1200].reset_index(drop=True)\n",
    "\n",
    "# Fix target label\n",
    "label_encodings = {\n",
    "    'pants-fire': 0, \n",
    "    'false':      0, \n",
    "    'barely-true':1, \n",
    "    'half-true':  1, \n",
    "    'mostly-true':2,\n",
    "    'true':       2\n",
    "}\n",
    "df['target'] = df['label'].apply(lambda x: label_encodings[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finished-browser",
   "metadata": {},
   "source": [
    "### Glove Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "attended-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Glove file\n",
    "words = pd.read_table(\"glove.6B.100d.txt\", sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n",
    "# Generate Glove dictionary\n",
    "glove = {word:words.iloc[idx].values for (word,idx) in zip(words.index,range(words.shape[0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "narrow-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text into words\n",
    "df['words'] = df['statement'].apply(lambda x: x.replace('?',' ?').replace('.',' .').\\\n",
    "                                    lower().split())\n",
    "# Generate the list of all vocab words in our data\n",
    "target_vocab = list(itertools.chain.from_iterable(df['words']))\n",
    "target_vocab = list(set(target_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "compound-insured",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We found 945 out of 4876 words not in the Glove model\n"
     ]
    }
   ],
   "source": [
    "# Generate the weights_matrix, which is the matrix of word embeddings that we\n",
    "# pass into Pytorch. It contains len(target_vocab) rows for each of the words,\n",
    "# each represented by a length-100 vector – taken from the Glove embedding\n",
    "weights_matrix = np.zeros((len(target_vocab),100))\n",
    "\n",
    "error_count = 0\n",
    "word_to_idx = {}\n",
    "for i, word in enumerate(target_vocab):\n",
    "    word_to_idx[word] = i\n",
    "    try: \n",
    "        weights_matrix[i] = glove[word]\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(100,))\n",
    "        error_count += 1\n",
    "        \n",
    "print(f\"We found {error_count} out of {len(target_vocab)} words not in the Glove model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "electric-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text using the indices\n",
    "df['text_idx'] = df['words'].apply(lambda lst: np.array([word_to_idx[w] for w in lst]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-judge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-guitar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "imperial-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "hollow-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyNN(nn.Module):\n",
    "    def __init__(self, weights_matrix, hidden_size, num_layers):\n",
    "        super(self).__init__()\n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "    def forward(self, inp, hidden):\n",
    "        return self.gru(self.embedding(inp), hidden)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(self.num_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "collective-german",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super() argument 1 must be type, not ToyNN",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-f031968f80e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToyNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-36-1ecf98da8067>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, weights_matrix, hidden_size, num_layers)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mToyNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_embeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_emb_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super() argument 1 must be type, not ToyNN"
     ]
    }
   ],
   "source": [
    "mod = ToyNN(weights_matrix, 100, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-stationery",
   "metadata": {},
   "source": [
    "### BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fallen-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate BERT embeddings\n",
    "bert_embedding = BertEmbedding()\n",
    "df['emb'] = df['statement'].apply(lambda x: bert_embedding(x.lower().split('\\n')))\n",
    "\n",
    "# Returns one BERT embedding (i.e. list of 768 numbers) per word\n",
    "# Per sentence, average over all the words\n",
    "df['emb_avg'] = df['emb'].apply(lambda x: np.array(x[0][1], dtype=float).mean(axis=0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-patient",
   "metadata": {},
   "source": [
    "### FakeBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "partial-sussex",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeBERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FakeBERT, self).__init__()\n",
    "        \n",
    "        # Conv1D Layer 1 + Maxpool\n",
    "        self.conv_1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=1)\n",
    "        self.sigm_1 = nn.ReLU()\n",
    "        self.pool_1 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Conv1D Layer 2 + Maxpool\n",
    "        self.conv_2 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=4, stride=1)\n",
    "        self.sigm_2 = nn.ReLU()\n",
    "        self.pool_2 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Conv1D Layer 3 + Maxpool\n",
    "        self.conv_3 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5, stride=1)\n",
    "        self.sigm_3 = nn.ReLU()\n",
    "        self.pool_3 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Conv1D Layer 4 + Maxpool\n",
    "        self.conv_4 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5, stride=1)\n",
    "        self.sigm_4 = nn.ReLU()\n",
    "        self.pool_4 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Conv1D Layer 5 + Maxpool\n",
    "        self.conv_5 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=5, stride=1)\n",
    "        self.sigm_5 = nn.ReLU()\n",
    "        self.pool_5 = nn.MaxPool1d(kernel_size=5, stride=5)\n",
    "        \n",
    "        # Fully connected layer\n",
    "        self.full_1 = nn.Linear(17,3)\n",
    "        self.soft_1 = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Generate the 3 1D conv layers\n",
    "        conv_1 = self.pool_1(self.sigm_1(self.conv_1(x)))        \n",
    "        conv_2 = self.pool_2(self.sigm_2(self.conv_2(x)))        \n",
    "        conv_3 = self.pool_3(self.sigm_3(self.conv_3(x)))\n",
    "        \n",
    "        # Concatenate the 3 layers\n",
    "        cat = torch.cat((conv_1,conv_2,conv_3),2)\n",
    "        \n",
    "        # Pass the concatenated output through 2 1D conv layers\n",
    "        conv_4 = self.pool_4(self.sigm_4(self.conv_4(cat)))        \n",
    "        conv_5 = self.pool_5(self.sigm_5(self.conv_5(conv_4)))  \n",
    "        \n",
    "        # Flatten the output\n",
    "        flat_1 = conv_5.flatten()\n",
    "        \n",
    "        # Pass through fully connected layer\n",
    "        full_1 = self.soft_1(self.full_1(flat_1))\n",
    "        \n",
    "        return full_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dietary-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(output, targets):\n",
    "\n",
    "    predicted = [int(y_pred.detach().argmax(-1)) for y_pred in output]\n",
    "    targets = [int(y) for y in targets]\n",
    "    correct = sum(a==b for (a,b) in zip(predicted, targets))\n",
    "    accuracy = 100*correct/len(targets) \n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "equal-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_x(x):\n",
    "    return torch.Tensor(x).unsqueeze(0).unsqueeze(0)\n",
    "def format_y(y):\n",
    "    return torch.Tensor([y]).to(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "postal-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data,\n",
    "          test,\n",
    "          num_epochs = 10,\n",
    "          batch_size = 100,\n",
    "          learning_rate = 0.01):\n",
    "    \n",
    "    # Instantiate model & optimization \n",
    "    model = FakeBERT()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Iterate over epochs\n",
    "    for ep in range(num_epochs):\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        # Iterate over batches\n",
    "        for i in range(data.shape[0]//batch_size):\n",
    "            \n",
    "            # Declare loss\n",
    "            loss_func = nn.CrossEntropyLoss()\n",
    "            loss = torch.tensor(0.0)\n",
    "            \n",
    "            for idx in range(i*batch_size, (i+1)*batch_size):\n",
    "                \n",
    "                # Declare features and target labels\n",
    "                X = format_x(data['emb_avg'][idx])\n",
    "                y = format_y(data['target'][idx])\n",
    "\n",
    "                # Get predictions from model\n",
    "                pred = model(X).unsqueeze(0)\n",
    "\n",
    "                # Calculate loss\n",
    "                loss += loss_func(pred, y)\n",
    "            \n",
    "            # Backpropagate\n",
    "            loss.backward()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # Evaluate model\n",
    "        model.eval()\n",
    "        \n",
    "        # Prepare test data\n",
    "        test_X = [format_x(x) for x in test['emb_avg']]\n",
    "        test_y = [format_y(y) for y in test['target']]\n",
    "            \n",
    "        # Evaluate on test data\n",
    "        test_pred = [model(x) for x in test_X]\n",
    "        test_accuracy = get_accuracy(test_pred, test_y)\n",
    "        \n",
    "        # Print accuracy\n",
    "        print(f\"Test accuracy: {test_accuracy} at epoch: {ep}\")\n",
    "\n",
    "    return test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "differential-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.iloc[:1000].reset_index(drop=True)\n",
    "test = df.iloc[1000:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "technical-thailand",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:51: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 35.5 at epoch: 0\n",
      "Test accuracy: 35.5 at epoch: 1\n",
      "Test accuracy: 35.5 at epoch: 2\n",
      "Test accuracy: 35.5 at epoch: 3\n",
      "Test accuracy: 35.5 at epoch: 4\n",
      "Test accuracy: 35.5 at epoch: 5\n",
      "Test accuracy: 35.5 at epoch: 6\n",
      "Test accuracy: 35.5 at epoch: 7\n",
      "Test accuracy: 35.5 at epoch: 8\n",
      "Test accuracy: 35.5 at epoch: 9\n"
     ]
    }
   ],
   "source": [
    "test_data = train(data, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "entitled-invitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4109], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3756, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3759, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3757, 0.4109], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2136, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2134, 0.3757, 0.4108], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4107], grad_fn=<SoftmaxBackward>),\n",
       " tensor([0.2135, 0.3758, 0.4108], grad_fn=<SoftmaxBackward>)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-parade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
